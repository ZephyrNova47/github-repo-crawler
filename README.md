# CASE STUDY 5

[Gitstar ranking](https://gitstar-ranking.com/repositories) l√† m·ªôt trang web th√∫ v·ªã ƒë·ªÉ th·ªëng k√™ c√°c trang ƒë∆∞·ª£c ƒë√°nh gi√° sao nhi·ªÅu nh·∫•t tr√™n Github. Nhi·ªám v·ª• trong b√†i n√†y l√† d·ª±ng m·ªôt crawler c√≥ th·ªÉ thu th·∫≠p ƒë∆∞·ª£c th√¥ng tin c√°c b·∫£n release c·ªßa 5000 repository nhi·ªÅu sao nh·∫•t Github.

## üöÄ H∆∞·ªõng d·∫´n c√†i ƒë·∫∑t

### 1. Clone repository

```bash
git clone <your-repo-url>
cd <ten-thu-muc-repo>
```

### 2. Di chuy·ªÉn v√†o th∆∞ m·ª•c th·ª±c nghi·ªám mu·ªën ch·∫°y

```bash
cd <1 trong 4 foler>
```

### 3. Kh·ªüi t·∫°o d·ªØ li·ªáu

Trong th∆∞ m·ª•c th·ª±c nghi·ªám th∆∞·ªùng c√≥ m·ªôt th∆∞ m·ª•c `setup-data` ho·∫∑c m·ª•c t√™n kh√°c nh∆∞ng c√≥ docker-compose file l√† ƒë∆∞·ª£c

```bash
cd setup-data
docker-compose up
```

Sau khi xong, quay l·∫°i th∆∞ m·ª•c th·ª±c nghi·ªám:

```bash
cd ..
go run cmd/main.go
```

L·ªánh tr√™n s·∫Ω kh·ªüi ch·∫°y server t·∫°i `localhost:<port>`.

---

## üì° API c√≥ s·∫µn

Sau khi server kh·ªüi ƒë·ªông, b·∫°n c√≥ th·ªÉ g·ªçi c√°c API nh∆∞ sau:

### Repositories
- `GET /api/repos/crawl`: crawl to√†n b·ªô repositories
- `GET /api/repos/{repoID}`: l·∫•y th√¥ng tin m·ªôt repository

### Releases
- `GET /api/releases/crawl`: crawl to√†n b·ªô releases
- `GET /api/releases/{releaseID}`: l·∫•y th√¥ng tin m·ªôt release
- `GET /api/releases/{releaseID}/commits`: crawl commit theo release

### Commits
- `GET /api/commits/crawl`: crawl to√†n b·ªô commits
- `GET /api/commits/{commitID}`: l·∫•y th√¥ng tin m·ªôt commit

---

## üìù L∆∞u √Ω

- Log h·ªá th·ªëng ƒë∆∞·ª£c l∆∞u t·∫°i th∆∞ m·ª•c `logs` trong t·ª´ng th·ª±c nghi·ªám.
  
## ‚öôÔ∏è C√¥ng ngh·ªá s·ª≠ d·ª•ng

- **Go (Golang)**: ng√¥n ng·ªØ l·∫≠p tr√¨nh ch√≠nh ƒë·ªÉ x√¢y d·ª±ng server v√† c√°c th√†nh ph·∫ßn logic
- **[Colly](https://github.com/gocolly/colly)**: th∆∞ vi·ªán crawler m·∫°nh m·∫Ω cho Go
- **[Chi Router](https://github.com/go-chi/chi)**: router HTTP nh·∫π v√† nhanh
- **[Logrus](https://github.com/sirupsen/logrus)**: logging framework
- **[Viper](https://github.com/spf13/viper)**: qu·∫£n l√Ω c·∫•u h√¨nh ·ª©ng d·ª•ng
- **[GORM](https://gorm.io/)**: ORM t∆∞∆°ng t√°c v·ªõi c∆° s·ªü d·ªØ li·ªáu
- **Docker Compose**: ph·ª•c v·ª• vi·ªác kh·ªüi t·∫°o c∆° s·ªü d·ªØ li·ªáu d·ªÖ d√†ng qua `setup-data`

## üß± Ki·∫øn tr√∫c & thi·∫øt k·∫ø

- **Queue-Based Load Leveling**: d·ªØ li·ªáu ƒë∆∞·ª£c ƒë∆∞a v√†o h√†ng ƒë·ª£i (queue) thay v√¨ ghi tr·ª±c ti·∫øp v√†o DB, gi√∫p tƒÉng t·ªëc ƒë·ªô crawl v√† gi·∫£m t·∫£i cho DB
- **Circuit Breaker Pattern**

---
  
# üí° Solution

## üìä K·∫øt qu·∫£ th·ª±c nghi·ªám
<table>
  <thead>
    <tr>
      <th> </th>
      <th colspan="3">Repos </th>
      <th colspan="3">Releases </th>
      <th colspan="3">Commits</th>
    </tr>
    <tr>
      <!-- D√≤ng header th·ª© hai ƒë·ªÉ ƒë√°nh t√™n hai c·ªôt con c·ªßa Col B -->
      <th></th>
      <th>crawled</th>
      <th>time (s)</th>
      <th>%error</th>
      <th>crawled</th>
      <th>time (s) </th>
      <th>%error</th>
      <th>crawled</th>
      <th>time (s) </th>
      <th>%error</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Baseline</td>
      <td>5000</td>
      <td>17.783</td>
      <td>0%</td>
      <td>1890</td>
      <td>1h53</td>
      <td>0%</td>
      <td>_</td>
      <td>_</td>
      <td>0%</td>
    </tr>
    <tr>
      <td>Exp 1</td>
      <td>5000</td>
      <td>5.3</td>
      <td>0%</td>
      <td>45837</td>
      <td>15p34</td>
      <td>0%</td>
      <td>36822</td>
      <td>13p56</td>
      <td>0%</td>
    </tr>
    <tr>
      <td>Exp 2</td>
      <td>5000</td>
      <td>4.3</td>
      <td>0%</td>
      <td>25690</td>
      <td>8p28</td>
      <td>0%</td>
      <td>37682</td>
      <td>12p55</td>
      <td>0%</td>
    </tr>
    <tr>
      <td>Exp 3</td>
      <td>5000</td>
      <td>6.5</td>
      <td>0%</td>
      <td>9835</td>
      <td>6p28</td>
      <td>0%</td>
      <td>6570</td>
      <td>4p14</td>
      <td>0%</td>
    </tr>
  </tbody>
</table>

# üìÉ M√¥ t·∫£ t·ª´ng th·ª≠ nghi·ªám

## Baseline

Baseline l√† m·ªôt crawler si√™u ƒë∆°n gi·∫£n, ch·ªâ c√≥ th·ªÉ c√†o d·ªØ li·ªáu ƒë∆°n thu·∫ßn t·ª± ƒë·ªông, m√† ch∆∞a c√≥ b·∫•t k·ª≥ x·ª≠ l√Ω gi√∫p t·ªëi ∆∞u v·ªÅ m·∫∑t th·ªùi gian v√† l∆∞·ª£ng d·ªØ li·ªáu crawled ƒë∆∞·ª£c. 

C√°c v·∫•n ƒë·ªÅ baseline n√†y g·∫∑p ph·∫£i:
- Database g·∫∑p qu√° nhi·ªÅu truy v·∫•n ghi -> ngh·∫Ωn
- T·ªëc ƒë·ªô crawl d·ªØ li·ªáu v·ªÅ r·∫•t ch·∫≠m do q√∫a nhi·ªÅu truy v·∫•n ghi m√† m·ªói l·∫ßn ch·ªâ ghi v√†o ƒë∆∞·ª£c c√≥ 1 record c·ªßa d·ªØ li·ªáu
- Data crawled v·ªÅ kh√¥ng ƒë∆∞·ª£c nhi·ªÅu do ngh·∫Ωn t·∫Øc x·∫£y ra

C√°c nguy√™n nh√¢n d·∫´n ƒë·∫øn nh·ªØng v·∫•n ƒë·ªÅ tr√™n:
- Thao t√°c ghi v√†o database ch∆∞a t·ªëi ∆∞u
- Ch∆∞a s·ª≠ d·ª•ng c√°c c∆° ch·∫ø gi√∫p crawl nhi·ªÅu lu·ªìng d·ªØ li·ªáu c√πng l√∫c

## Exp 1
Crawl ƒëa lu·ªìng (th·ª±c nghi·ªám 4 - 10 lu·ªìng), ƒë·ªìng th·ªùi s·ª≠ d·ª•ng batch ƒë·ªÉ cho ph√©p ghi batch 100 records c√πng 1 l√∫c.
=> C√°c c·∫£i ti·∫øn:
1. **T·∫≠n d·ª•ng ƒë·ªó tr·ªÖ m·∫°ng**  
   - T·∫°o nhi·ªÅu ƒë·ªìng th·ªùi, t·∫≠n d·ª•ng t·ªëi ƒëa ƒë·ªô tr·ªÖ m·∫°ng t·ª´ ƒë√≥ r√∫t ng·∫Øn th·ªùi gian crawl

2. **·ªîn ƒë·ªãnh h∆°n so v·ªõi 1 lu·ªìng ƒë∆°n**  
   - N·∫øu m·ªôt lu·ªìng b·ªã block (timeout, delay), c√°c lu·ªìng kh√°c v·∫´n ti·∫øp t·ª•c ho·∫°t ƒë·ªông, ngƒÉn t√¨nh tr·∫°ng ‚Äúƒëi·ªÉm ch·∫øt‚Äù to√†n b·ªô qu√° tr√¨nh crawl so v·ªõi vi·ªác ch·ªâ s·ª≠ d·ª•ng m·ªói 1 lu·ªìng nh∆∞ baseline.

4. **Gi·∫£m s·ªë l∆∞·ª£ng truy v·∫•n DB nh·ªù batch insert**  
   - Gom 100 k·∫øt qu·∫£ crawl v√†o m·ªôt l√¥ (batch) tr∆∞·ªõc khi m·ªôt thao t√°c ghi  
   - S·ª≠ d·ª•ng transaction ƒë·∫£m b·∫£o t√≠nh nh·∫•t qu√°n c·ªßa d·ªØ li·ªáu trong qu√° tr√¨nh crawl v√† insert l∆∞·ª£ng l·ªõn data t·ª´ crawler

5. **TƒÉng t·ªëc ƒë·ªô ghi & gi·∫£m latency tail**  
   - Ghi 100 b·∫£n ghi c√πng l√∫c t·∫≠n d·ª•ng t·ªët I/O throughput.  
   - Gi·∫£m th·ªùi gian ch·ªù ƒë·ª£i cho m·ªói batch d·ªØ li·ªáu, gi√∫p crawler kh√¥ng ph·∫£i ch·ªù qu√° l√¢u gi·ªØa c√°c batch.

## Exp 2
Crawl d√πng queue, c√°c data crawl c√†o v·ªÅ ƒë∆∞·ª£c nh√©t v√†o queue ƒë·ªÉ ƒë·ª£i khi n√†o database r·∫£nh th√¨ s·∫Ω th·ª±c hi·ªán ghi v√†o db, ƒë·ªìng th·ªùi c≈©ng √°p d·ª•ng c∆° ch·∫ø batch-insert nh∆∞ pipeline 1
=> C√°c c·∫£i ti·∫øn ƒë·∫°t ƒë∆∞·ª£c:
1. **TƒÉng throughput cho crawler**  
   - Crawler ch·ªâ c·∫ßn ƒë·∫©y k·∫øt qu·∫£ v√†o queue m√† kh√¥ng ph·∫£i ch·ªù ghi xong v√†o DB => Gi·∫£m th·ªùi gian ch·ªù, vi·ªác crawl ƒë∆∞·ª£c th·ª±c hi·ªán li√™n t·ª•c t·ª´ ƒë√≥ gi·∫£m th·ªùi gian crawl xu·ªëng  

2. **ƒêi·ªÅu ti·∫øt t·∫£i (Back‚Äëpressure)**  
   - Queue l∆∞u tr·ªØ l∆∞·ª£ng data ch·ªù ghi. Khi DB b·∫≠n, consumer gi·∫£m t·ªëc ƒë·ªô ghi t·ª± ƒë·ªông, crawler v·∫´n ti·∫øp t·ª•c (ƒë·∫øn ng∆∞·ª°ng queue).

3. **Gi·∫£m s·ªë l∆∞·ª£ng truy v·∫•n DB nh·ªù batch insert v√† tƒÉng t·ªëc ƒë·ªô ghi** (L√Ω do t∆∞∆°ng t·ª± exp 1 v√¨ s·ª≠ d·ª•ng batch-inserted)

## Exp 3
√Åp d·ª•ng Circuit Breaker
=> C√°c c·∫£i ti·∫øn:
1. **Tr√°nh s·ª± c·ªë**  
   - Trong tr∆∞·ªùng server ƒë√≠ch li√™n t·ª•c response l·ªói, c∆° ch·∫ø Circuit Breaker s·∫Ω b·∫£o v·ªá c√°c API kh√¥ng b·ªã g·ªçi li√™n t·ª•c => Crawler kh√¥ng b·ªã s·∫≠p ho√†n to√†n
   - Sau m·ªôt kho·∫£ng th·ªùi gian th√¨ crawler c√≥ th·ªÉ t·ª± ph·ª•c h·ªìi ƒë∆∞·ª£c nh·ªù c∆° ch·∫ø half-open c·ªßa Circuit Breaker

2. **TƒÉng ƒë·ªô ·ªïn ƒë·ªãnh v√† hi·ªáu su·∫•t c·ªßa h·ªá th·ªëng**
   - Circuit Breaker lu√¥n gi·ªØ cho 3 API kh√¥ng b·ªã s·∫≠p (nh∆∞ tr√™n ƒë√£ gi·∫£i th√≠ch)
   - Crawler b·ªè qua nh·ªØng request l·ªói => Ti·∫øt ki·ªám th·ªùi gian crawl
     
3. **Gi·∫£m s·ªë l∆∞·ª£ng truy v·∫•n DB nh·ªù batch insert v√† tƒÉng t·ªëc ƒë·ªô ghi** (L√Ω do t∆∞∆°ng t·ª± exp 1 v√¨ s·ª≠ d·ª•ng batch-inserted)

